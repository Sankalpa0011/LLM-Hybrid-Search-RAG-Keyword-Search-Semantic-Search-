{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1luGztwAsQtCU9mQ723VldfU_RzrIO9E-",
      "authorship_tag": "ABX9TyP8OQAKMDXN9lYKjoJacmRz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sankalpa0011/LLM-Hybrid-Search-RAG-Keyword-Search-Semantic-Search-/blob/main/Hybrid_Search_RAG_Langchain_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hybrid Search RAG** using Langchain and OpenAI"
      ],
      "metadata": {
        "id": "WreMXqTcuMtu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uIi-vHXsCdBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d56662-d53c-4b2b-9f37-e89fd189b14b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pypdf -q\n",
        "!pip install langchain -q\n",
        "!pip install langchain_community -q\n",
        "!pip install langchain_openai -q\n",
        "!pip install langchain_chroma -q\n",
        "!pip install rank_bm25 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "MYhgRSsduW3p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize OpenAI LLM"
      ],
      "metadata": {
        "id": "RTA7c59Nu1Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "LrWGSQSyu2a_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Embedding Model"
      ],
      "metadata": {
        "id": "14piPs50vB62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "L6Ia0OS1u9dU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load PDF Document"
      ],
      "metadata": {
        "id": "ePD-9bW3vJib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmZs8UrYvWRh",
        "outputId": "4cff3271-1d51-41d5-b7d6-c2cae56dde9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader=PyPDFLoader(\"/content/drive/MyDrive/CodeProLK DL/LLM Hybrid Search RAG (Keyword Search + Semantic Search)/Sankalpa_Portfolio.pdf\")\n",
        "\n",
        "docs=loader.load()"
      ],
      "metadata": {
        "id": "T8a8YqiAvHa6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Documents into Chunks"
      ],
      "metadata": {
        "id": "PQ2-OtMpv1xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=250,chunk_overlap=30)\n",
        "\n",
        "chunks = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "rVCrBa2xvpCg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2sj-50Rv62o",
        "outputId": "8e3ee10b-389f-49f2-8c3b-f4d1a50ae9c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Semantic Search Retriever"
      ],
      "metadata": {
        "id": "iTL5fhBCwAJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vectorstore=Chroma.from_documents(chunks, embedding_model)\n",
        "\n",
        "vectorstore_retreiver = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "ts_ePM5dv7QC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore_retreiver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9GKqx9awFiW",
        "outputId": "aff42502-31ac-4f49-b921-ac744120939b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7ba387f99060>, search_kwargs={'k': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Keyword Search Retriever"
      ],
      "metadata": {
        "id": "XYvQgHcIwJsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import BM25Retriever\n",
        "\n",
        "keyword_retriever = BM25Retriever.from_documents(chunks)\n",
        "\n",
        "keyword_retriever.k =  2"
      ],
      "metadata": {
        "id": "7CmbZEJFwGH6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lOETd_uwNd4",
        "outputId": "b50b7189-9cfe-46c3-e895-5728d902cc35"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7ba384a51a50>, k=2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Hybrid Search Retriever"
      ],
      "metadata": {
        "id": "U3Jvh_X9wRAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(retrievers = [vectorstore_retreiver, keyword_retriever], weights = [0.5, 0.5])"
      ],
      "metadata": {
        "id": "S4QyeU89wNzk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7DAVClOwTtp",
        "outputId": "bc9c9477-37be-4a08-c6b6-33a1b3a28a2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7ba387f99060>, search_kwargs={'k': 2}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7ba384a51a50>, k=2)], weights=[0.5, 0.5])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Prompt Template"
      ],
      "metadata": {
        "id": "HpnHgBaKwW7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Define a message template for the chatbot\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "# Create a chat prompt template from the message\n",
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ],
      "metadata": {
        "id": "MN3eke_MwUxF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create RAG Chain with Hybrid Search"
      ],
      "metadata": {
        "id": "R5qBwQnLwc7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\n",
        "      \"context\": ensemble_retriever,\n",
        "      \"question\": RunnablePassthrough()\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        ")"
      ],
      "metadata": {
        "id": "aIJ5ZB9CwZA8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Invoke RAG Chain with Example Questions"
      ],
      "metadata": {
        "id": "L7F_nhAFwjni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\"what are the skills that have sankalpa?\")\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jocFLopuwf1g",
        "outputId": "45bb520e-afde-47c1-9ec6-8fc225e8fb22"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The skills that Sankalpa possesses include decision-making, innovation, developing intelligent systems, enhancing human interaction with technology, sharing knowledge through workshops, lectures, and tutorials, and continuous learning and collaboration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## keyword_retriever, vectorstore_retreiver, ensemble_retriever"
      ],
      "metadata": {
        "id": "A_oiROPlw2j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in keyword_retriever.invoke(\"what are the skills that have sankalpa?\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrGwT5D_wpfY",
        "outputId": "2436aa2e-af94-46b1-e3fb-67cd1b7769b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Educator and Innovator\n",
            "Sankalpa actively engages with tech communities, sharing knowledge through workshops, lectures,\n",
            "and tutorials. Recent lectures on Management Information Systems have received widespread\n",
            "---------------------\n",
            "Through continuous learning and collaboration, Sankalpa aspires to leave a lasting impression on\n",
            "the tech world while making a difference in people's lives.\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in vectorstore_retreiver.invoke(\"what are the skills that have sankalpa?\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xZNYGRuw9Lb",
        "outputId": "97951f91-42f5-4db6-c54f-6b24a120441f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision-making. With an unwavering commitment to innovation, Sankalpa specializes in developing\n",
            "intelligent systems that enhance human interaction with technology, particularly through applications\n",
            "in health, education, and accessibility.\n",
            "---------------------\n",
            "Sankalpa's Portfolio\n",
            "Introduction to Sankalpa's Portfolio\n",
            "Background and Vision\n",
            "Motivation and Inspiration\n",
            "Sankalpa's journey in technology began with a desire to bridge the gap between data and\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in ensemble_retriever.invoke(\"what are the skills that have sankalpa?\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mApWFWOow_Zq",
        "outputId": "bf6af41f-a900-4c22-afc9-783b9e24bf02"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decision-making. With an unwavering commitment to innovation, Sankalpa specializes in developing\n",
            "intelligent systems that enhance human interaction with technology, particularly through applications\n",
            "in health, education, and accessibility.\n",
            "---------------------\n",
            "Educator and Innovator\n",
            "Sankalpa actively engages with tech communities, sharing knowledge through workshops, lectures,\n",
            "and tutorials. Recent lectures on Management Information Systems have received widespread\n",
            "---------------------\n",
            "Sankalpa's Portfolio\n",
            "Introduction to Sankalpa's Portfolio\n",
            "Background and Vision\n",
            "Motivation and Inspiration\n",
            "Sankalpa's journey in technology began with a desire to bridge the gap between data and\n",
            "---------------------\n",
            "Through continuous learning and collaboration, Sankalpa aspires to leave a lasting impression on\n",
            "the tech world while making a difference in people's lives.\n",
            "---------------------\n"
          ]
        }
      ]
    }
  ]
}